{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3079e370",
   "metadata": {},
   "source": [
    "# Guía Completa de Técnicas de Prompting\n",
    "\n",
    "## 1. Técnicas Básicas\n",
    "\n",
    "### 1.1 Claridad y Especificidad\n",
    "**Principio**: Ser claro y específico en lugar de vago.\n",
    "\n",
    "**❌ Prompt vago:**\n",
    "```\n",
    "Escribe sobre marketing\n",
    "```\n",
    "\n",
    "**✅ Prompt específico:**\n",
    "```\n",
    "Escribe un artículo de 800 palabras sobre estrategias de marketing digital para pequeñas empresas de e-commerce, enfocándose en redes sociales, SEO y email marketing.\n",
    "```\n",
    "\n",
    "### 1.2 Contexto Detallado\n",
    "**Principio**: Proporcionar contexto relevante para obtener respuestas más precisas.\n",
    "\n",
    "**Ejemplo:**\n",
    "```\n",
    "Actúa como un consultor de recursos humanos con 10 años de experiencia. Una startup tecnológica de 25 empleados necesita implementar un sistema de evaluación de desempeño. Proporciona un plan detallado considerando el presupuesto limitado y la cultura informal de la empresa.\n",
    "```\n",
    "\n",
    "## 2. Técnicas de Estructura\n",
    "\n",
    "### 2.1 Chain of Thought (Cadena de Pensamiento)\n",
    "**Principio**: Pedir al AI que muestre su razonamiento paso a paso.\n",
    "\n",
    "**Ejemplo:**\n",
    "```\n",
    "Resuelve este problema paso a paso:\n",
    "Una tienda vende camisetas a $15 cada una. Si compras 3 o más, hay un 20% de descuento. Si compras 5 o más, hay un 30% de descuento. ¿Cuánto costaría comprar 7 camisetas?\n",
    "\n",
    "Piensa paso a paso:\n",
    "1. Identifica qué descuento aplica\n",
    "2. Calcula el precio con descuento\n",
    "3. Calcula el total\n",
    "```\n",
    "\n",
    "### 2.2 Few-Shot Learning (Aprendizaje con Pocos Ejemplos)\n",
    "**Principio**: Proporcionar ejemplos para establecer el patrón deseado.\n",
    "\n",
    "**Ejemplo:**\n",
    "```\n",
    "Convierte estas descripciones a formato de producto e-commerce:\n",
    "\n",
    "Ejemplo 1:\n",
    "Input: \"Zapatos deportivos Nike rojos talla 42\"\n",
    "Output: \"Zapatillas Nike Running - Rojo | Talla 42 | Ideales para correr y entrenar\"\n",
    "\n",
    "Ejemplo 2:\n",
    "Input: \"Laptop HP 8GB RAM 256GB SSD\"\n",
    "Output: \"Laptop HP Pavilion - 8GB RAM, 256GB SSD | Perfecta para trabajo y estudio\"\n",
    "\n",
    "Ahora convierte:\n",
    "Input: \"Auriculares inalámbricos Sony cancelación ruido\"\n",
    "```\n",
    "\n",
    "### 2.3 Role Playing (Interpretación de Rol)\n",
    "**Principio**: Asignar un rol específico al AI para obtener respuestas más especializadas.\n",
    "\n",
    "**Ejemplo:**\n",
    "```\n",
    "Actúa como un chef profesional con especialización en cocina mediterránea. Un cliente quiere un menú para una cena romántica de 3 platos usando ingredientes de temporada de primavera. El presupuesto es moderado y uno de los comensales es vegetariano.\n",
    "```\n",
    "\n",
    "## 3. Técnicas Avanzadas\n",
    "\n",
    "### 3.1 Tree of Thoughts (Árbol de Pensamientos)\n",
    "**Principio**: Explorar múltiples líneas de razonamiento antes de llegar a una conclusión.\n",
    "\n",
    "**Ejemplo:**\n",
    "```\n",
    "Necesito elegir una plataforma para mi tienda online. Analiza estas opciones considerando múltiples perspectivas:\n",
    "\n",
    "Opciones: Shopify, WooCommerce, Magento\n",
    "\n",
    "Evalúa desde estas perspectivas:\n",
    "1. Perspectiva técnica (facilidad de uso, personalización)\n",
    "2. Perspectiva financiera (costos iniciales y recurrentes)\n",
    "3. Perspectiva de crecimiento (escalabilidad)\n",
    "4. Perspectiva de marketing (herramientas integradas)\n",
    "\n",
    "Para cada perspectiva, analiza los pros y contras de cada opción, luego sintetiza una recomendación final.\n",
    "```\n",
    "\n",
    "### 3.2 Constitutional AI\n",
    "**Principio**: Establecer principios o reglas que deben seguirse en la respuesta.\n",
    "\n",
    "**Ejemplo:**\n",
    "```\n",
    "Crea un plan de marketing para una aplicación de fitness siguiendo estos principios:\n",
    "1. Debe ser ético y no usar tácticas manipuladoras\n",
    "2. Debe ser inclusivo para todos los tipos de cuerpo\n",
    "3. Debe enfocarse en bienestar general, no solo en apariencia\n",
    "4. Debe ser honesto sobre los resultados esperados\n",
    "5. Debe promover hábitos sostenibles a largo plazo\n",
    "```\n",
    "\n",
    "### 3.3 Prompt Chaining (Encadenamiento)\n",
    "**Principio**: Dividir tareas complejas en pasos secuenciales.\n",
    "\n",
    "**Ejemplo:**\n",
    "```\n",
    "Paso 1: Analiza las tendencias actuales del mercado de aplicaciones móviles de salud mental\n",
    "Paso 2: Basándote en el análisis anterior, identifica 3 nichos específicos con potencial\n",
    "Paso 3: Para el nicho más prometedor, desarrolla un concepto de aplicación\n",
    "Paso 4: Crea un plan de lanzamiento para esa aplicación\n",
    "```\n",
    "\n",
    "## 4. Técnicas de Control de Salida\n",
    "\n",
    "### 4.1 Formato Específico\n",
    "**Principio**: Especificar exactamente cómo debe estructurarse la respuesta.\n",
    "\n",
    "**Ejemplo:**\n",
    "```\n",
    "Analiza la estrategia de contenido de una marca de ropa sostenible y presenta tu análisis en este formato:\n",
    "\n",
    "## Análisis de Estrategia de Contenido\n",
    "\n",
    "**Marca:** [Nombre]\n",
    "**Audiencia objetivo:** [Descripción]\n",
    "\n",
    "### Fortalezas\n",
    "- [Lista de 3-4 puntos]\n",
    "\n",
    "### Debilidades\n",
    "- [Lista de 3-4 puntos]\n",
    "\n",
    "### Recomendaciones\n",
    "1. **Corto plazo (1-3 meses):** [Acciones específicas]\n",
    "2. **Mediano plazo (3-6 meses):** [Acciones específicas]\n",
    "3. **Largo plazo (6+ meses):** [Acciones específicas]\n",
    "\n",
    "### Métricas de éxito\n",
    "- [3-4 KPIs específicos]\n",
    "```\n",
    "\n",
    "### 4.2 Restricciones de Longitud y Tono\n",
    "**Ejemplo:**\n",
    "```\n",
    "Explica el concepto de inteligencia artificial en exactamente 100 palabras, usando un tono conversacional como si le hablaras a un adolescente de 15 años. Evita jerga técnica y usa analogías simples.\n",
    "```\n",
    "\n",
    "### 4.3 Formato JSON/Estructurado\n",
    "**Ejemplo:**\n",
    "```\n",
    "Analiza este producto y devuelve el resultado en formato JSON:\n",
    "\n",
    "{\n",
    "  \"producto\": \"[nombre del producto]\",\n",
    "  \"categoria\": \"[categoría principal]\",\n",
    "  \"puntos_fuertes\": [\"[lista de fortalezas]\"],\n",
    "  \"puntos_debiles\": [\"[lista de debilidades]\"],\n",
    "  \"precio_sugerido\": \"[rango de precio]\",\n",
    "  \"mercado_objetivo\": \"[descripción del público]\",\n",
    "  \"puntuacion_viabilidad\": \"[1-10]\"\n",
    "}\n",
    "```\n",
    "\n",
    "## 5. Técnicas de Optimización\n",
    "\n",
    "### 5.1 Prompts Negativos\n",
    "**Principio**: Especificar qué NO hacer para evitar resultados no deseados.\n",
    "\n",
    "**Ejemplo:**\n",
    "```\n",
    "Escribe un artículo sobre inversión para principiantes.\n",
    "\n",
    "NO incluyas:\n",
    "- Consejos específicos de acciones o criptomonedas\n",
    "- Promesas de ganancias garantizadas\n",
    "- Jerga financiera compleja sin explicar\n",
    "- Recomendaciones de productos financieros específicos\n",
    "\n",
    "SÍ incluye:\n",
    "- Conceptos básicos explicados claramente\n",
    "- Principios generales de inversión\n",
    "- Advertencias sobre riesgos\n",
    "- Pasos prácticos para empezar\n",
    "```\n",
    "\n",
    "### 5.2 Iteración y Refinamiento\n",
    "**Ejemplo de proceso iterativo:**\n",
    "```\n",
    "Primera iteración:\n",
    "\"Crea un plan de contenido para redes sociales\"\n",
    "\n",
    "Segunda iteración:\n",
    "\"El plan anterior es muy genérico. Créalo específicamente para una panadería artesanal local, enfocándose en Instagram y Facebook, con 3 publicaciones semanales durante 1 mes\"\n",
    "\n",
    "Tercera iteración:\n",
    "\"Perfecto. Ahora incluye las mejores horas para publicar y hashtags específicos para cada publicación\"\n",
    "```\n",
    "\n",
    "### 5.3 Meta-Prompting\n",
    "**Principio**: Pedir al AI que ayude a mejorar el prompt.\n",
    "\n",
    "**Ejemplo:**\n",
    "```\n",
    "Quiero crear un prompt para generar ideas de contenido para mi blog de viajes. Mi prompt actual es: \"Dame ideas para mi blog de viajes\"\n",
    "\n",
    "¿Cómo puedo mejorar este prompt para obtener ideas más específicas y útiles? Sugiere una versión mejorada y explica por qué sería más efectiva.\n",
    "```\n",
    "\n",
    "## 6. Técnicas para Casos Específicos\n",
    "\n",
    "### 6.1 Análisis y Síntesis\n",
    "```\n",
    "Actúa como un analista de mercado. Analiza la siguiente información sobre la industria de food delivery y sintetiza:\n",
    "\n",
    "[Datos/información]\n",
    "\n",
    "Estructura tu análisis en:\n",
    "1. Tendencias principales (3-4 puntos clave)\n",
    "2. Oportunidades identificadas\n",
    "3. Riesgos y desafíos\n",
    "4. Recomendación estratégica (1 párrafo)\n",
    "```\n",
    "\n",
    "### 6.2 Creatividad Guiada\n",
    "```\n",
    "Genera 5 conceptos creativos para una campaña publicitaria de una marca de café orgánico. Para cada concepto incluye:\n",
    "\n",
    "- Título de la campaña\n",
    "- Concepto central en 1 línea\n",
    "- Canal principal (digital, tradicional, experiencial)\n",
    "- Público objetivo específico\n",
    "- Elemento diferenciador\n",
    "\n",
    "Criterios: Debe ser auténtico, sostenible y memorable.\n",
    "```\n",
    "\n",
    "### 6.3 Resolución de Problemas\n",
    "```\n",
    "Problema: Una pequeña empresa de software tiene alta rotación de empleados (40% anual).\n",
    "\n",
    "Usando el método de los \"5 Por Qués\", analiza las posibles causas raíz y luego propone 3 soluciones específicas y accionables, priorizándolas por impacto y facilidad de implementación.\n",
    "```\n",
    "\n",
    "## 7. Mejores Prácticas\n",
    "\n",
    "### 7.1 Checklist de un Buen Prompt\n",
    "- [ ] Contexto claro establecido\n",
    "- [ ] Objetivo específico definido\n",
    "- [ ] Formato de salida especificado\n",
    "- [ ] Ejemplos incluidos (si es necesario)\n",
    "- [ ] Restricciones y limitaciones mencionadas\n",
    "- [ ] Criterios de éxito establecidos\n",
    "\n",
    "### 7.2 Errores Comunes a Evitar\n",
    "1. **Ser demasiado vago:** \"Ayúdame con marketing\"\n",
    "2. **No dar contexto:** Asumir que el AI conoce tu situación específica\n",
    "3. **Pedir demasiado en un solo prompt:** Intentar resolver múltiples problemas complejos\n",
    "4. **No especificar formato:** Dejar que el AI decida cómo estructurar la respuesta\n",
    "5. **No iterar:** Conformarse con la primera respuesta sin refinar\n",
    "\n",
    "### 7.3 Consejos para Prompts Más Efectivos\n",
    "- **Usa verbos de acción específicos:** \"Analiza\", \"Compara\", \"Diseña\", \"Evalúa\"\n",
    "- **Incluye métricas cuando sea relevante:** \"Aumentar engagement en 25%\"\n",
    "- **Especifica el nivel de detalle:** \"Explicación básica\", \"Análisis profundo\"\n",
    "- **Menciona el público objetivo:** \"Para directivos\", \"Para principiantes\"\n",
    "- **Establece deadline o urgencia si es relevante:** \"Para implementar la próxima semana\"\n",
    "\n",
    "## 8. Plantillas Útiles\n",
    "\n",
    "### Plantilla para Análisis de Competencia\n",
    "```\n",
    "Analiza a [COMPETIDOR] en la industria de [INDUSTRIA] considerando:\n",
    "\n",
    "**Contexto:** [Tu empresa/situación]\n",
    "**Objetivo:** [Qué buscas lograr con este análisis]\n",
    "\n",
    "**Áreas a analizar:**\n",
    "1. Propuesta de valor\n",
    "2. Estrategia de pricing\n",
    "3. Canales de distribución\n",
    "4. Estrategia de marketing\n",
    "5. Fortalezas y debilidades\n",
    "\n",
    "**Formato de entrega:** [Especificar formato deseado]\n",
    "**Próximos pasos:** Incluir 3 recomendaciones accionables\n",
    "```\n",
    "\n",
    "### Plantilla para Brainstorming\n",
    "```\n",
    "Necesito generar ideas para [PROBLEMA/DESAFÍO].\n",
    "\n",
    "**Contexto:**\n",
    "- Industria: [industria]\n",
    "- Audiencia: [descripción]\n",
    "- Presupuesto: [rango]\n",
    "- Restricciones: [limitaciones]\n",
    "\n",
    "**Tipo de ideas buscadas:** [específico, creativo, práctico, etc.]\n",
    "**Cantidad:** [número de ideas]\n",
    "**Formato:** Para cada idea incluir [título, descripción, pros/contras, nivel de dificultad]\n",
    "```\n",
    "\n",
    "### Plantilla para Resolución de Problemas\n",
    "```\n",
    "**Problema:** [Descripción clara del problema]\n",
    "**Impacto:** [Cómo afecta al negocio/proyecto]\n",
    "**Contexto:** [Información relevante]\n",
    "**Recursos disponibles:** [Tiempo, presupuesto, equipo]\n",
    "**Restricciones:** [Limitaciones]\n",
    "\n",
    "**Proceso solicitado:**\n",
    "1. Análisis de causas raíz\n",
    "2. 3-5 opciones de solución\n",
    "3. Evaluación de cada opción (pros/contras/recursos)\n",
    "4. Recomendación final con plan de implementación\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c215e160",
   "metadata": {},
   "source": [
    "## 🧠 What Is RAG and Why Should You Care?\n",
    "\n",
    "**RAG (Retrieval Augmented Generation)** is one of the most powerful techniques in modern AI applications. Let's break it down:\n",
    "\n",
    "| Component | What It Does | Why It Matters |\n",
    "|-----------|--------------|----------------|\n",
    "| **Retrieval** | Finds relevant information from your documents | Ensures answers come from *your* data, not just the AI's training |\n",
    "| **Augmentation** | Enhances the AI's knowledge with this specific information | Makes responses accurate and up-to-date |\n",
    "| **Generation** | Creates human-like responses using the retrieved information | Delivers insights in natural, easy-to-understand language |\n",
    "\n",
    "<div style=\"background-color: #effaf5; border: 1px solid #0d9488; padding: 15px; margin: 20px 0; border-radius: 5px;\">\n",
    "<h4 style=\"color: #000000; margin-top: 0;\">💡 Real-World Analogy</h4>\n",
    "<p style=\"color: #000000;\">Think of RAG as the difference between:</p>\n",
    "<ul style=\"color: #000000;\">\n",
    "<li><strong>A general knowledge expert</strong> who studied years ago (standard LLM)</li>\n",
    "<li><strong>A specialist with your documents open</strong> in front of them, referencing exact paragraphs as they answer your questions (RAG system)</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "## 🛠️ Our Exciting Toolkit\n",
    "\n",
    "We'll be using several cutting-edge tools to build our RAG system:\n",
    "\n",
    "| Tool | What It Is | Why It's Amazing |\n",
    "|------|------------|------------------|\n",
    "| **Ollama** | An open-source platform that runs AI models locally on your computer | Privacy (your data never leaves your machine), no API costs, and complete control |\n",
    "| **ChromaDB** | A specialized database for storing and searching \"vector embeddings\" | Lightning-fast semantic search that understands meaning, not just keywords |\n",
    "| **LangChain** | A framework that connects AI components together like building blocks | Makes complex AI workflows simple and customizable |\n",
    "| **Gradio** | A tool for creating web interfaces for AI models | Turns your code into a professional-looking application in minutes |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b573c28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain langchain_ollama gradio chromadb pypdf langchain_community"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd694c20",
   "metadata": {},
   "source": [
    "# 🎯 What We'll Build Together\n",
    "\n",
    "By the end of this tutorial, you'll have created:\n",
    "\n",
    "```\n",
    "📄 Documents → 🔪 Chunker → 🧮 Vector DB → 🔍 Retriever → 🤖 LLM → 💬 Answer\n",
    "```\n",
    "\n",
    "A complete RAG system that can:\n",
    "\n",
    "1. **Process PDF documents** of your choice\n",
    "2. **Break them into smart chunks** that preserve meaning\n",
    "3. **Transform text into vectors** that capture semantic meaning\n",
    "4. **Store everything efficiently** for lightning-fast retrieval\n",
    "5. **Find the most relevant information** for any question\n",
    "6. **Generate accurate, helpful responses** with proper citations\n",
    "\n",
    "<div style=\"background-color: #ffe4e6; border-left: 6px solid #be123c; padding: 15px; margin: 20px 0; border-radius: 5px;\">\n",
    "<h3 style=\"color: #000000; margin-top: 0;\">🔥 Why This Matters For Your Career</h3>\n",
    "<p style=\"color: #000000;\">RAG systems are at the forefront of practical AI applications. At MAIA Academy, we've seen how companies are rapidly adopting this technology to:</p>\n",
    "<ul style=\"color: #000000;\">\n",
    "<li>Build intelligent document assistants</li>\n",
    "<li>Create knowledge bases that actually answer questions</li>\n",
    "<li>Develop customer support systems that handle complex queries</li>\n",
    "<li>Implement research tools that synthesize information from multiple sources</li>\n",
    "</ul>\n",
    "<p style=\"color: #000000;\">The skills you'll learn today are directly transferable to real-world AI projects and align perfectly with our <strong>Foundations of AI Development</strong> and <strong>Deep Learning & LLMs</strong> modules!</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dbeeda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\demst\\Desktop\\rag\\rag\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "import sys\n",
    "import tempfile\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# LangChain imports\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "# Gradio for web interface\n",
    "import gradio as gr\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b9af63",
   "metadata": {},
   "source": [
    "## 2. Setting the Stage: Configuration\n",
    "\n",
    "<div style=\"background-color: #2d333b; padding: 20px; border-radius: 8px; margin-bottom: 20px; border-left: 6px solid #58a6ff;\">\n",
    "  <h3 style=\"color: #ffffff; margin-top: 0;\">System Configuration Parameters</h3>\n",
    "  <p style=\"color: #ffffff;\">Before we build our RAG system, we need to configure some important settings—like tuning a new instrument before a performance. These parameters will determine how our system processes and interacts with documents.</p>\n",
    "</div>\n",
    "\n",
    "<table style=\"width: 100%; border-collapse: collapse; margin: 20px 0; background-color: #22272e;\">\n",
    "  <tr>\n",
    "    <td style=\"padding: 15px; border: 1px solid #444c56; width: 200px;\"><strong style=\"color: #58a6ff;\">PERSIST_DIRECTORY</strong></td>\n",
    "    <td style=\"padding: 15px; border: 1px solid #444c56; color: #adbac7;\">Where we'll store our \"data safe\" (the vector database) on disk. This allows our system to remember what it learned even after restarting.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"padding: 15px; border: 1px solid #444c56;\"><strong style=\"color: #58a6ff;\">CHUNK_SIZE</strong></td>\n",
    "    <td style=\"padding: 15px; border: 1px solid #444c56; color: #adbac7;\">How big each text piece will be (in characters). This affects how much context the AI has when answering questions.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"padding: 15px; border: 1px solid #444c56;\"><strong style=\"color: #58a6ff;\">CHUNK_OVERLAP</strong></td>\n",
    "    <td style=\"padding: 15px; border: 1px solid #444c56; color: #adbac7;\">How much the pieces overlap to maintain context between chunks and ensure no information is lost at the boundaries.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"padding: 15px; border: 1px solid #444c56;\"><strong style=\"color: #58a6ff;\">PDF_URLS</strong></td>\n",
    "    <td style=\"padding: 15px; border: 1px solid #444c56; color: #adbac7;\">The documents we'll use as our knowledge base (our \"reference library\"). These are the sources the system will learn from.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"padding: 15px; border: 1px solid #444c56;\"><strong style=\"color: #58a6ff;\">LLM_MODEL</strong></td>\n",
    "    <td style=\"padding: 15px; border: 1px solid #444c56; color: #adbac7;\">The \"brain\" that processes the context and generates answers (like llama3 or other models available in Ollama).</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"padding: 15px; border: 1px solid #444c56;\"><strong style=\"color: #58a6ff;\">EMBEDDING_MODEL</strong></td>\n",
    "    <td style=\"padding: 15px; border: 1px solid #444c56; color: #adbac7;\">The \"translator\" that converts text into numerical vectors that capture meaning. Different models balance between speed and accuracy.</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "<div style=\"background-color: #2d333b; border: 1px solid #444c56; padding: 20px; border-radius: 8px; margin: 20px 0;\">\n",
    "  <h3 style=\"color: #58a6ff; margin-top: 0;\">💡 What's This Chunk Stuff?</h3>\n",
    "  <p style=\"color: #adbac7;\">Think of cutting a big sandwich. If the pieces are huge, you get more filling but it's hard to bite. If they're tiny, you bite easy but might miss the full flavor. Overlap is like leaving a bit of the last bite on the next one so you don't lose track of the overall taste.</p>\n",
    "  \n",
    "  <div style=\"display: flex; justify-content: space-between; margin-top: 20px; text-align: center;\">\n",
    "    <div style=\"flex: 1; margin: 0 10px;\">\n",
    "      <p style=\"color: #58a6ff;\"><strong>Large Chunks (2000+)</strong></p>\n",
    "      <p style=\"color: #adbac7;\">✅ More context<br>✅ Better for complex topics<br>❌ Less precise retrieval<br>❌ Slower processing</p>\n",
    "    </div>\n",
    "    <div style=\"flex: 1; margin: 0 10px;\">\n",
    "      <p style=\"color: #58a6ff;\"><strong>Medium Chunks (800-1200)</strong></p>\n",
    "      <p style=\"color: #adbac7;\">✅ Balanced approach<br>✅ Good for most cases<br>✅ Reasonable speed<br>✅ Decent precision</p>\n",
    "    </div>\n",
    "    <div style=\"flex: 1; margin: 0 10px;\">\n",
    "      <p style=\"color: #58a6ff;\"><strong>Small Chunks (300-500)</strong></p>\n",
    "      <p style=\"color: #adbac7;\">✅ Very precise retrieval<br>✅ Fast processing<br>❌ Limited context<br>❌ May miss broader concepts</p>\n",
    "    </div>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align: center; background-color: #22272e; padding: 10px; border-radius: 5px; margin-top: 20px;\">\n",
    "  <p style=\"color: #ff7b72; font-weight: bold;\">⚠️ Warning</p>\n",
    "  <p style=\"color: #adbac7;\">This notebook is designed to be read with a dark background. If you program with a white background, just know that you're a complete psychopath and a danger to society.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33657fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameters\n",
    "PERSIST_DIRECTORY = \"chroma_db\"\n",
    "CHUNK_SIZE = 1000\n",
    "CHUNK_OVERLAP = 200\n",
    "PDF_URLS = [ \n",
    "    \"https://www.ine.es/daco/daco42/ecp/ecp0123.pdf\",\n",
    "    \"https://fundacionalternativas.org/wp-content/uploads/2023/10/PERSONAS_MIGRANTES_v02.pdf\"\n",
    "]\n",
    "LLM_MODEL = \"llama3.2:1b\"  # Using a small Llama model for faster responses\n",
    "EMBEDDING_MODEL = \"all-minilm\"  # Small, fast embedding model (22M parameters)\n",
    "TEMPERATURE = 0.1  # Lower temperature for more deterministic outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07093b22",
   "metadata": {},
   "source": [
    "## 3. The Heart of It: RAGSystem Class\n",
    "\n",
    "Now, let’s create the main “robot” that does all the work: the RAGSystem class. This robot gets ready with all the tools it needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f67b0c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGSystem:\n",
    "    def __init__(self, pdf_urls: List[str], persist_directory: str = PERSIST_DIRECTORY):\n",
    "        self.pdf_urls = pdf_urls\n",
    "        self.persist_directory = persist_directory\n",
    "        self.documents = []\n",
    "        self.vectorstore = None\n",
    "        self.llm = None\n",
    "        self.chain = None\n",
    "        \n",
    "        # Initialize the LLM with streaming capability\n",
    "        callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "        self.llm = ChatOllama(\n",
    "            model=LLM_MODEL,\n",
    "            temperature=TEMPERATURE,\n",
    "            callback_manager=callback_manager\n",
    "        )\n",
    "        \n",
    "        # Initialize embeddings\n",
    "        self.embeddings = OllamaEmbeddings(model=EMBEDDING_MODEL)\n",
    "        \n",
    "        logger.info(f\"Initialized RAG system with {len(pdf_urls)} PDFs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3102d2",
   "metadata": {},
   "source": [
    "## 3. Building Our RAG System\n",
    "\n",
    "<div style=\"background-color: #2d333b; padding: 5px; border-radius: 4px; margin-bottom: 10px;\">\n",
    "  <h3 style=\"color: #58a6ff; margin: 10px;\">3.1 Loading and Chopping Documents</h3>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: #22272e; padding: 15px; border-radius: 8px; border-left: 4px solid #7ee787; margin-bottom: 20px;\">\n",
    "  <p style=\"color: #adbac7;\">The first crucial step in our RAG pipeline is to read PDFs and slice them into manageable chunks. This process transforms raw documents into pieces our system can effectively process.</p>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: #2d333b; border: 1px solid #444c56; padding: 20px; border-radius: 8px; margin: 20px 0;\">\n",
    "  <h4 style=\"color: #7ee787; margin-top: 0;\">📚 Why Do We Chop?</h4>\n",
    "  \n",
    "  <p style=\"color: #adbac7;\">Imagine a huge cake: you can't eat it all at once, so you cut it into slices. Same with documents:</p>\n",
    "  \n",
    "  <ul style=\"color: #adbac7; margin-left: 20px;\">\n",
    "    <li><strong style=\"color: #d2a8ff;\">AI has a \"small tummy\"</strong> (a context window that limits how much text it can process at once)</li>\n",
    "    <li><strong style=\"color: #d2a8ff;\">Small chunks help find exact answers fast</strong> (better retrieval precision)</li>\n",
    "    <li><strong style=\"color: #d2a8ff;\">It makes the system quicker and less likely to choke</strong> (more efficient processing)</li>\n",
    "  </ul>\n",
    "  \n",
    "  <div style=\"margin-top: 25px; background-color: #22272e; padding: 15px; border-radius: 5px; border: 1px dashed #444c56;\">\n",
    "    <h5 style=\"color: #58a6ff; margin-top: 0;\">🔍 Technical Insight: The Chunking Process</h5>\n",
    "    <p style=\"color: #adbac7;\">Our system uses a <code style=\"background-color: #2d333b; padding: 2px 5px; border-radius: 3px; color: #ff7b72;\">RecursiveCharacterTextSplitter</code> that intelligently divides text based on:</p>\n",
    "    <ul style=\"color: #adbac7;\">\n",
    "      <li>Natural boundaries (paragraphs, sentences)</li>\n",
    "      <li>Configured chunk size (how many characters per chunk)</li>\n",
    "      <li>Strategic overlap to maintain context between chunks</li>\n",
    "    </ul>\n",
    "    <p style=\"color: #adbac7;\">This ensures that each chunk contains coherent, meaningful information rather than arbitrary text divisions.</p>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<div style=\"display: flex; background-color: #22272e; border-radius: 8px; overflow: hidden; margin: 20px 0;\">\n",
    "  <div style=\"flex: 1; padding: 15px; border-right: 1px solid #444c56;\">\n",
    "    <p style=\"color: #58a6ff; font-weight: bold; margin-top: 0;\">Document Loading</p>\n",
    "    <p style=\"color: #adbac7; margin-bottom: 0;\">👉 Reading PDFs using PyPDFLoader</p>\n",
    "    <p style=\"color: #adbac7; margin-bottom: 0;\">👉 Extracting text and metadata</p>\n",
    "    <p style=\"color: #adbac7; margin-bottom: 0;\">👉 Handling multiple documents</p>\n",
    "  </div>\n",
    "  <div style=\"flex: 1; padding: 15px; border-right: 1px solid #444c56;\">\n",
    "    <p style=\"color: #58a6ff; font-weight: bold; margin-top: 0;\">Document Chunking</p>\n",
    "    <p style=\"color: #adbac7; margin-bottom: 0;\">👉 Splitting into smaller pieces</p>\n",
    "    <p style=\"color: #adbac7; margin-bottom: 0;\">👉 Maintaining logical boundaries</p>\n",
    "    <p style=\"color: #adbac7; margin-bottom: 0;\">👉 Creating overlapping sections</p>\n",
    "  </div>\n",
    "  <div style=\"flex: 1; padding: 15px;\">\n",
    "    <p style=\"color: #58a6ff; font-weight: bold; margin-top: 0;\">Result</p>\n",
    "    <p style=\"color: #adbac7; margin-bottom: 0;\">👉 Dozens or hundreds of chunks</p>\n",
    "    <p style=\"color: #adbac7; margin-bottom: 0;\">👉 Each ~1000 characters long</p>\n",
    "    <p style=\"color: #adbac7; margin-bottom: 0;\">👉 Ready for embedding creation</p>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: #2d333b; border-left: 4px solid #f97583; padding: 15px; border-radius: 5px; margin-top: 20px;\">\n",
    "  <p style=\"color: #adbac7; margin: 0;\"><strong style=\"color: #f97583;\">⚠️ Common Pitfall:</strong> Setting your chunk size too small (under 300 characters) or too large (over 2000 characters) can severely impact your system's performance. Start with ~1000 and adjust based on your specific documents and query needs.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9248f3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents(self) -> None:\n",
    "    \"\"\"Load and split PDF documents\"\"\"\n",
    "    logger.info(\"Loading and processing PDFs...\")\n",
    "    \n",
    "    # Text splitter for chunking documents\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=CHUNK_SIZE,\n",
    "        chunk_overlap=CHUNK_OVERLAP,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    "    )\n",
    "    \n",
    "    all_pages = []\n",
    "    for url in self.pdf_urls:\n",
    "        try:\n",
    "            loader = PyPDFLoader(url)\n",
    "            pages = loader.load()\n",
    "            logger.info(f\"Loaded {len(pages)} pages from {url}\")\n",
    "            all_pages.extend(pages)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading PDF from {url}: {e}\")\n",
    "    \n",
    "    # Split the documents into chunks\n",
    "    self.documents = text_splitter.split_documents(all_pages)\n",
    "    logger.info(f\"Created {len(self.documents)} document chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c68a46",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #2d333b; padding: 5px; border-radius: 4px; margin-bottom: 10px;\">\n",
    "  <h3 style=\"color: #58a6ff; margin: 10px;\">3.2 Storing in a Vector Database</h3>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: #22272e; padding: 15px; border-radius: 8px; border-left: 4px solid #f0883e; margin-bottom: 20px;\">\n",
    "  <p style=\"color: #adbac7;\">After chunking our documents, we need to store them in a way that allows for intelligent searching. This is where vectors and ChromaDB come into play.</p>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: #2d333b; border: 1px solid #444c56; padding: 20px; border-radius: 8px; margin: 20px 0;\">\n",
    "  <h4 style=\"color: #f0883e; margin-top: 0;\">🧮 What Are Vectors?</h4>\n",
    "  \n",
    "  <p style=\"color: #adbac7;\">Think of each chunk as a person, and we give it a unique \"fingerprint\" based on what it says. These fingerprints are actually lists of numbers that capture meaning.</p>\n",
    "  \n",
    "  <div style=\"display: flex; margin-top: 20px; background-color: #22272e; padding: 15px; border-radius: 8px;\">\n",
    "    <div style=\"flex: 1; padding-right: 15px;\">\n",
    "      <p style=\"color: #adbac7; font-style: italic; margin-top: 0;\">\"I like the sun\"</p>\n",
    "      <p style=\"color: #d2a8ff; font-family: monospace; font-size: 0.9em;\">[0.12, -0.33, 0.65, ...]</p>\n",
    "    </div>\n",
    "    <div style=\"flex: 1; padding-left: 15px; border-left: 1px dashed #444c56;\">\n",
    "      <p style=\"color: #adbac7; font-style: italic; margin-top: 0;\">\"I love the heat\"</p>\n",
    "      <p style=\"color: #d2a8ff; font-family: monospace; font-size: 0.9em;\">[0.15, -0.28, 0.61, ...]</p>\n",
    "    </div>\n",
    "  </div>\n",
    "  \n",
    "  <p style=\"color: #adbac7; margin-top: 20px;\">These sentences get similar vector \"fingerprints\" because they express similar concepts. This lets us search by <strong>meaning</strong>, not just exact words.</p>\n",
    "</div>\n",
    "\n",
    "<div style=\"display: flex; background-color: #22272e; border-radius: 8px; overflow: hidden; margin: 20px 0; border: 1px solid #444c56;\">\n",
    "  <div style=\"flex: 1; padding: 15px; display: flex; flex-direction: column; align-items: center; text-align: center; border-right: 1px solid #444c56;\">\n",
    "    <div style=\"background-color: #2d333b; width: 50px; height: 50px; border-radius: 50%; display: flex; align-items: center; justify-content: center; margin-bottom: 10px;\">\n",
    "      <span style=\"color: #58a6ff; font-weight: bold; font-size: 1.5em;\">1</span>\n",
    "    </div>\n",
    "    <p style=\"color: #f0883e; font-weight: bold; margin: 5px 0;\">Convert</p>\n",
    "    <p style=\"color: #adbac7; margin: 5px 0;\">Text → Vector</p>\n",
    "  </div>\n",
    "  <div style=\"flex: 1; padding: 15px; display: flex; flex-direction: column; align-items: center; text-align: center; border-right: 1px solid #444c56;\">\n",
    "    <div style=\"background-color: #2d333b; width: 50px; height: 50px; border-radius: 50%; display: flex; align-items: center; justify-content: center; margin-bottom: 10px;\">\n",
    "      <span style=\"color: #58a6ff; font-weight: bold; font-size: 1.5em;\">2</span>\n",
    "    </div>\n",
    "    <p style=\"color: #f0883e; font-weight: bold; margin: 5px 0;\">Store</p>\n",
    "    <p style=\"color: #adbac7; margin: 5px 0;\">In ChromaDB</p>\n",
    "  </div>\n",
    "  <div style=\"flex: 1; padding: 15px; display: flex; flex-direction: column; align-items: center; text-align: center;\">\n",
    "    <div style=\"background-color: #2d333b; width: 50px; height: 50px; border-radius: 50%; display: flex; align-items: center; justify-content: center; margin-bottom: 10px;\">\n",
    "      <span style=\"color: #58a6ff; font-weight: bold; font-size: 1.5em;\">3</span>\n",
    "    </div>\n",
    "    <p style=\"color: #f0883e; font-weight: bold; margin: 5px 0;\">Retrieve</p>\n",
    "    <p style=\"color: #adbac7; margin: 5px 0;\">By Similarity</p>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: #22272e; padding: 20px; border-radius: 8px; margin: 20px 0; border: 1px solid #444c56;\">\n",
    "  <h4 style=\"color: #58a6ff; margin-top: 0;\">In Plain English:</h4>\n",
    "  \n",
    "  <p style=\"color: #adbac7;\">1. <strong>We transform text into numbers</strong> using the embedding model (all-minilm)</p>\n",
    "  <p style=\"color: #adbac7;\">2. <strong>We store these numbers in ChromaDB</strong> along with the original text</p>\n",
    "  <p style=\"color: #adbac7;\">3. <strong>When you ask a question</strong>, we convert your question to a vector too</p>\n",
    "  <p style=\"color: #adbac7;\">4. <strong>ChromaDB finds chunks with similar vectors</strong> to your question</p>\n",
    "  <p style=\"color: #adbac7;\">5. <strong>These similar chunks</strong> likely contain the answer you need</p>\n",
    "</div>\n",
    "\n",
    "<div style=\"display: flex; background-color: #22272e; border-radius: 8px; margin: 20px 0;\">\n",
    "  <div style=\"flex: 1; padding: 20px;\">\n",
    "    <h5 style=\"color: #7ee787; margin-top: 0;\">💡 Why This Is Cool</h5>\n",
    "    <ul style=\"color: #adbac7; list-style-type: none; padding-left: 0;\">\n",
    "      <li style=\"margin-bottom: 8px;\">✅ <strong>Finds similar concepts</strong>, even with different words</li>\n",
    "      <li style=\"margin-bottom: 8px;\">✅ <strong>Lightning-fast search</strong> of large document collections</li>\n",
    "      <li style=\"margin-bottom: 8px;\">✅ <strong>Works across languages</strong> (Spanish \"sol\" ≈ English \"sun\")</li>\n",
    "      <li>✅ <strong>More accurate</strong> than keyword searching</li>\n",
    "    </ul>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: #2d333b; border-left: 4px solid #d2a8ff; padding: 15px; border-radius: 5px; margin-top: 20px;\">\n",
    "  <p style=\"color: #adbac7; margin: 0;\"><strong style=\"color: #d2a8ff;\">🚀 Pro Tip:</strong> Think of it like searching a music library - you find songs that \"sound similar\" to the one you like, not just songs with the exact same title.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e6c7086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectorstore(self) -> None:\n",
    "    \"\"\"Create a fresh vector database\"\"\"\n",
    "    # Remove any existing database\n",
    "    if os.path.exists(self.persist_directory):\n",
    "        import shutil\n",
    "        logger.info(f\"Removing existing vectorstore at {self.persist_directory}\")\n",
    "        shutil.rmtree(self.persist_directory, ignore_errors=True)\n",
    "    \n",
    "    # Create a new vectorstore\n",
    "    logger.info(\"Creating new vectorstore...\")\n",
    "    if not self.documents:\n",
    "        self.load_documents()\n",
    "    \n",
    "    # Create a temporary directory for the database\n",
    "    # This helps avoid permission issues on some systems\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    logger.info(f\"Using temporary directory for initial database creation: {temp_dir}\")\n",
    "    \n",
    "    try:\n",
    "        # First create in temp directory\n",
    "        self.vectorstore = Chroma.from_documents(\n",
    "            documents=self.documents,\n",
    "            embedding=self.embeddings,\n",
    "            persist_directory=temp_dir\n",
    "        )\n",
    "        \n",
    "        # Now create the real directory\n",
    "        if not os.path.exists(self.persist_directory):\n",
    "            os.makedirs(self.persist_directory)\n",
    "            \n",
    "        # And create the final vectorstore\n",
    "        self.vectorstore = Chroma.from_documents(\n",
    "            documents=self.documents,\n",
    "            embedding=self.embeddings,\n",
    "            persist_directory=self.persist_directory\n",
    "        )\n",
    "        self.vectorstore.persist()\n",
    "        \n",
    "        logger.info(f\"Vectorstore created successfully with {len(self.documents)} documents\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error creating vectorstore: {e}\")\n",
    "        raise\n",
    "    finally:\n",
    "        # Clean up temp directory\n",
    "        if os.path.exists(temp_dir):\n",
    "            import shutil\n",
    "            shutil.rmtree(temp_dir, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7095c38d",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #2d333b; padding: 5px; border-radius: 4px; margin-bottom: 10px;\">\n",
    "  <h3 style=\"color: #58a6ff; margin: 10px;\">3.3 Building the RAG Chain</h3>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: #22272e; padding: 15px; border-radius: 8px; border-left: 4px solid #79c0ff; margin-bottom: 20px;\">\n",
    "  <p style=\"color: #adbac7;\">Here's where our system turns into a \"detective.\" We connect all the components into a sequence that transforms questions into accurate answers.</p>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: #1c2128; padding: 20px; border-radius: 8px; margin: 20px 0; border: 1px solid #444c56;\">\n",
    "  <h4 style=\"color: #79c0ff; margin-top: 0; text-align: center; margin-bottom: 20px;\">The RAG Chain Components</h4>\n",
    "  \n",
    "  <!-- Retriever Component -->\n",
    "  <div style=\"background-color: #22272e; border-radius: 8px; padding: 15px; margin-bottom: 15px; border: 1px solid #444c56;\">\n",
    "    <div style=\"display: flex; align-items: center;\">\n",
    "      <div style=\"background-color: #2d333b; width: 50px; height: 50px; border-radius: 50%; display: flex; align-items: center; justify-content: center; margin-right: 15px;\">\n",
    "        <span style=\"font-size: 1.5em;\">🔍</span>\n",
    "      </div>\n",
    "      <div>\n",
    "        <p style=\"color: #79c0ff; margin: 0; font-weight: bold;\">The Searcher (Retriever)</p>\n",
    "      </div>\n",
    "    </div>\n",
    "    <div style=\"margin-top: 10px; padding-left: 65px;\">\n",
    "      <p style=\"color: #adbac7; margin: 0;\">Turns your question into a fingerprint and finds the closest matches in the database.</p>\n",
    "      <div style=\"background-color: #2d333b; padding: 8px; border-radius: 4px; margin-top: 10px;\">\n",
    "        <code style=\"color: #d2a8ff; font-size: 0.9em;\">retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})</code>\n",
    "      </div>\n",
    "    </div>\n",
    "  </div>\n",
    "  \n",
    "  <!-- Prompt Template Component -->\n",
    "  <div style=\"background-color: #22272e; border-radius: 8px; padding: 15px; margin-bottom: 15px; border: 1px solid #444c56;\">\n",
    "    <div style=\"display: flex; align-items: center;\">\n",
    "      <div style=\"background-color: #2d333b; width: 50px; height: 50px; border-radius: 50%; display: flex; align-items: center; justify-content: center; margin-right: 15px;\">\n",
    "        <span style=\"font-size: 1.5em;\">📝</span>\n",
    "      </div>\n",
    "      <div>\n",
    "        <p style=\"color: #79c0ff; margin: 0; font-weight: bold;\">The Instructions (Prompt)</p>\n",
    "      </div>\n",
    "    </div>\n",
    "    <div style=\"margin-top: 10px; padding-left: 65px;\">\n",
    "      <p style=\"color: #adbac7; margin: 0;\">Like a recipe: \"Be nice, use the chunks, cite your sources.\" This keeps answers helpful and trustworthy.</p>\n",
    "      <div style=\"background-color: #2d333b; padding: 8px; border-radius: 4px; margin-top: 10px;\">\n",
    "        <code style=\"color: #d2a8ff; font-size: 0.9em;\">prompt = PromptTemplate.from_template(template)</code>\n",
    "      </div>\n",
    "    </div>\n",
    "  </div>\n",
    "  \n",
    "  <!-- LLM Component -->\n",
    "  <div style=\"background-color: #22272e; border-radius: 8px; padding: 15px; margin-bottom: 15px; border: 1px solid #444c56;\">\n",
    "    <div style=\"display: flex; align-items: center;\">\n",
    "      <div style=\"background-color: #2d333b; width: 50px; height: 50px; border-radius: 50%; display: flex; align-items: center; justify-content: center; margin-right: 15px;\">\n",
    "        <span style=\"font-size: 1.5em;\">🧠</span>\n",
    "      </div>\n",
    "      <div>\n",
    "        <p style=\"color: #79c0ff; margin: 0; font-weight: bold;\">The AI (LLM)</p>\n",
    "      </div>\n",
    "    </div>\n",
    "    <div style=\"margin-top: 10px; padding-left: 65px;\">\n",
    "      <p style=\"color: #adbac7; margin: 0;\">Writes the final response based on the instructions and retrieved chunks.</p>\n",
    "      <div style=\"background-color: #2d333b; padding: 8px; border-radius: 4px; margin-top: 10px;\">\n",
    "        <code style=\"color: #d2a8ff; font-size: 0.9em;\">llm = ChatOllama(model=\"llama3\", temperature=0.1)</code>\n",
    "      </div>\n",
    "    </div>\n",
    "  </div>\n",
    "  \n",
    "  <!-- Output Parser Component -->\n",
    "  <div style=\"background-color: #22272e; border-radius: 8px; padding: 15px; margin-bottom: 0; border: 1px solid #444c56;\">\n",
    "    <div style=\"display: flex; align-items: center;\">\n",
    "      <div style=\"background-color: #2d333b; width: 50px; height: 50px; border-radius: 50%; display: flex; align-items: center; justify-content: center; margin-right: 15px;\">\n",
    "        <span style=\"font-size: 1.5em;\">✨</span>\n",
    "      </div>\n",
    "      <div>\n",
    "        <p style=\"color: #79c0ff; margin: 0; font-weight: bold;\">The Formatter (Parser)</p>\n",
    "      </div>\n",
    "    </div>\n",
    "    <div style=\"margin-top: 10px; padding-left: 65px;\">\n",
    "      <p style=\"color: #adbac7; margin: 0;\">Makes the response neat and clear for the user to read.</p>\n",
    "      <div style=\"background-color: #2d333b; padding: 8px; border-radius: 4px; margin-top: 10px;\">\n",
    "        <code style=\"color: #d2a8ff; font-size: 0.9em;\">StrOutputParser()</code>\n",
    "      </div>\n",
    "    </div>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<!-- Flow diagram -->\n",
    "<div style=\"background-color: #22272e; padding: 20px; border-radius: 8px; margin: 20px 0;\">\n",
    "  <h4 style=\"color: #79c0ff; margin-top: 0; text-align: center;\">How It All Flows Together</h4>\n",
    "  \n",
    "  <div style=\"display: flex; justify-content: center; align-items: center; flex-wrap: wrap; margin: 20px 0;\">\n",
    "    <div style=\"text-align: center; background-color: #2d333b; padding: 15px; border-radius: 8px; margin: 5px;\">\n",
    "      <div style=\"font-size: 2em; margin-bottom: 5px;\">❓</div>\n",
    "      <div style=\"color: #adbac7;\">Question</div>\n",
    "    </div>\n",
    "    <div style=\"font-size: 1.5em; margin: 0 10px; color: #adbac7;\">→</div>\n",
    "    <div style=\"text-align: center; background-color: #2d333b; padding: 15px; border-radius: 8px; margin: 5px;\">\n",
    "      <div style=\"font-size: 2em; margin-bottom: 5px;\">🔍</div>\n",
    "      <div style=\"color: #adbac7;\">Retriever</div>\n",
    "    </div>\n",
    "    <div style=\"font-size: 1.5em; margin: 0 10px; color: #adbac7;\">→</div>\n",
    "    <div style=\"text-align: center; background-color: #2d333b; padding: 15px; border-radius: 8px; margin: 5px;\">\n",
    "      <div style=\"font-size: 2em; margin-bottom: 5px;\">📝</div>\n",
    "      <div style=\"color: #adbac7;\">Prompt</div>\n",
    "    </div>\n",
    "    <div style=\"font-size: 1.5em; margin: 0 10px; color: #adbac7;\">→</div>\n",
    "    <div style=\"text-align: center; background-color: #2d333b; padding: 15px; border-radius: 8px; margin: 5px;\">\n",
    "      <div style=\"font-size: 2em; margin-bottom: 5px;\">🧠</div>\n",
    "      <div style=\"color: #adbac7;\">LLM</div>\n",
    "    </div>\n",
    "    <div style=\"font-size: 1.5em; margin: 0 10px; color: #adbac7;\">→</div>\n",
    "    <div style=\"text-align: center; background-color: #2d333b; padding: 15px; border-radius: 8px; margin: 5px;\">\n",
    "      <div style=\"font-size: 2em; margin-bottom: 5px;\">✨</div>\n",
    "      <div style=\"color: #adbac7;\">Parser</div>\n",
    "    </div>\n",
    "    <div style=\"font-size: 1.5em; margin: 0 10px; color: #adbac7;\">→</div>\n",
    "    <div style=\"text-align: center; background-color: #2d333b; padding: 15px; border-radius: 8px; margin: 5px;\">\n",
    "      <div style=\"font-size: 2em; margin-bottom: 5px;\">💡</div>\n",
    "      <div style=\"color: #adbac7;\">Answer</div>\n",
    "    </div>\n",
    "  </div>\n",
    "  \n",
    "  <div style=\"background-color: #1c2128; padding: 15px; border-radius: 8px; margin-top: 20px;\">\n",
    "    <p style=\"color: #adbac7; margin: 0; text-align: center;\">This entire chain is created with just a few lines of code:</p>\n",
    "    <div style=\"background-color: #2d333b; border-radius: 5px; padding: 15px; margin-top: 10px; font-family: monospace;\">\n",
    "      <pre style=\"color: #d2a8ff; margin: 0; overflow-x: auto; font-size: 0.9em;\">self.chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | self.llm\n",
    "    | StrOutputParser()\n",
    ")</pre>\n",
    "    </div>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: #2d333b; border-left: 4px solid #58a6ff; padding: 15px; border-radius: 5px; margin-top: 20px;\">\n",
    "  <p style=\"color: #adbac7; margin: 0;\"><strong style=\"color: #adbac7;\">💡 Pro Tip:</strong> The key to a good RAG system is balance. A great prompt template with poor retrieval won't work well, and perfect retrieval with bad instructions will still give bad answers. All pieces need to work together!</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a758ba67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_chain(self) -> None:\n",
    "    \"\"\"Set up the RAG chain for question answering\"\"\"\n",
    "    if not self.vectorstore:\n",
    "        self.create_vectorstore()\n",
    "    \n",
    "    # Create retriever with search parameters\n",
    "    retriever = self.vectorstore.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": 5}  # Return top 5 most relevant chunks\n",
    "    )\n",
    "    \n",
    "    # Define the prompt template\n",
    "    template = \"\"\"\n",
    "    ### INSTRUCTIONS: \n",
    "    You are an AI assistant dedicated to answering questions in a polite and professional manner. You must provide a helpful response to the user.\n",
    "    \n",
    "    (1) Be attentive to details: read the question and context thoroughly before answering.\n",
    "    (2) Begin your response with a friendly tone and reiterate the question to ensure you understood it.\n",
    "    (3) If the context allows you to answer the question, write a detailed, helpful, and easy-to-understand response, with sources referenced in the text. IF NOT: if you cannot find the answer, respond with an explanation, starting with: \"I couldn't find the information in the documents I have access to.\"\n",
    "    (4) Below your response, please list all referenced sources (i.e., document sections that support your claims).\n",
    "    (5) Review your answer to ensure you answered the question, the response is helpful and professional, and it's formatted to be easily readable.\n",
    "    \n",
    "    THINK STEP BY STEP\n",
    "    \n",
    "    Answer the following question using the provided context.\n",
    "    ### Question: {question} ###\n",
    "    ### Context: {context} ###     \n",
    "    ### Helpful Answer with Sources:\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = PromptTemplate.from_template(template)\n",
    "    \n",
    "    # Create the chain\n",
    "    self.chain = (\n",
    "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | self.llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    logger.info(\"RAG chain setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8af5a77",
   "metadata": {},
   "source": [
    "### 3.4 Answering Questions\n",
    "\n",
    "Time to shine! The robot takes your question, processes it, and gives you an answer. If something goes wrong, it politely lets you know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a65baa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(self, question: str) -> str:\n",
    "    \"\"\"\n",
    "    Answer a question using the RAG chain\n",
    "    \n",
    "    Args:\n",
    "        question: The question to answer\n",
    "        \n",
    "    Returns:\n",
    "        The answer to the question\n",
    "    \"\"\"\n",
    "    if not self.chain:\n",
    "        self.setup_chain()\n",
    "    \n",
    "    logger.info(f\"Answering question: {question}\")\n",
    "    try:\n",
    "        answer = self.chain.invoke(question)\n",
    "        return answer\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error answering question: {e}\")\n",
    "        return f\"Error processing your question: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8472cba3",
   "metadata": {},
   "source": [
    "## 4. A Window to the World: Gradio Interface\n",
    "\n",
    "Let’s make our robot user-friendly with a web interface.\n",
    "\n",
    "### 🌐 Why Gradio?\n",
    "It’s like building an app with Lego blocks: easy, fast, and you can use it from your phone or computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53c011a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gradio_interface(rag_system: RAGSystem) -> gr.Interface:\n",
    "    \"\"\"\n",
    "    Create a Gradio interface for the RAG system\n",
    "    \n",
    "    Args:\n",
    "        rag_system: The RAG system to use\n",
    "        \n",
    "    Returns:\n",
    "        A Gradio interface\n",
    "    \"\"\"\n",
    "    def get_answer(question: str) -> str:\n",
    "        \"\"\"Wrapper function for the Gradio interface\"\"\"\n",
    "        return rag_system.answer_question(question)\n",
    "    \n",
    "    # Gradio interface configuration\n",
    "    interface = gr.Interface(\n",
    "        fn=get_answer,\n",
    "        inputs=gr.Textbox(\n",
    "            placeholder=\"Ask a question about immigration...\",\n",
    "            label=\"Your Question\"\n",
    "        ),\n",
    "        outputs=gr.Markdown(label=\"Answer\"),\n",
    "        title=\"Document Intelligence System with LLM\",\n",
    "        description=\"Ask any question about immigration based on the loaded documents\",\n",
    "        theme=gr.themes.Soft(),\n",
    "        allow_flagging=\"never\",\n",
    "        examples=[\n",
    "            \"How many immigrants arrive each year?\",\n",
    "            \"What are the main countries of origin?\",\n",
    "            \"What economic impact does immigration have?\"\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483a5acb",
   "metadata": {},
   "source": [
    "## 5. Let’s Get It Running!\n",
    "\n",
    "The “start button” checks everything, tests a question, and opens the interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8319d580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() -> None:\n",
    "    \"\"\"Main function to run the RAG system\"\"\"\n",
    "    try:\n",
    "        # Display available models\n",
    "        print(\"\\n==== CHECKING OLLAMA MODELS ====\")\n",
    "        try:\n",
    "            import requests\n",
    "            response = requests.get(\"http://localhost:11434/api/tags\")\n",
    "            print(\"Available Ollama models:\")\n",
    "            if response.status_code == 200:\n",
    "                for model in response.json().get(\"models\", []):\n",
    "                    print(f\"- {model['name']}\")\n",
    "            else:\n",
    "                print(f\"Error checking Ollama models: {response.status_code}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error connecting to Ollama: {e}\")\n",
    "        \n",
    "        print(f\"\\nUsing LLM model: {LLM_MODEL}\")\n",
    "        print(f\"Using embedding model: {EMBEDDING_MODEL}\")\n",
    "        print(\"Make sure these models are available with 'ollama pull' commands.\")\n",
    "        \n",
    "        # Create and initialize the RAG system\n",
    "        rag_system = RAGSystem(pdf_urls=PDF_URLS)\n",
    "        \n",
    "        # Load documents and create vectorstore\n",
    "        rag_system.load_documents()\n",
    "        rag_system.create_vectorstore()\n",
    "        \n",
    "        # Test with a control question\n",
    "        logger.info(\"Testing with a control question...\")\n",
    "        test_answer = rag_system.answer_question(\"How many immigrants arrive each year?\")\n",
    "        logger.info(f\"Control answer received (length: {len(test_answer)})\")\n",
    "        \n",
    "        # Create and launch Gradio interface\n",
    "        logger.info(\"Launching Gradio interface...\")\n",
    "        interface = create_gradio_interface(rag_system)\n",
    "        interface.launch(share=False)  # Set share=True to create a public link\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred in the main function: {e}\")\n",
    "        print(f\"\\n\\nERROR: {str(e)}\\n\\n\")\n",
    "        print(\"\\nTROUBLESHOOTING TIPS:\")\n",
    "        print(\"1. Make sure Ollama is running: 'ollama serve'\")\n",
    "        print(f\"2. Make sure you have pulled the required models:\")\n",
    "        print(f\"   - ollama pull {LLM_MODEL}\")\n",
    "        print(f\"   - ollama pull {EMBEDDING_MODEL}\")\n",
    "        print(\"3. If you're still having dimension issues, try using a different embedding model by changing EMBEDDING_MODEL\")\n",
    "        print(\"4. Check that you have the required Python packages installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3001fcfd",
   "metadata": {},
   "source": [
    "## 6. Putting It Together\n",
    "\n",
    "Time to assemble our robot and make it run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "735f07f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAGSystem.load_documents = load_documents\n",
    "RAGSystem.create_vectorstore = create_vectorstore\n",
    "RAGSystem.setup_chain = setup_chain\n",
    "RAGSystem.answer_question = answer_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1810918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== CHECKING OLLAMA MODELS ====\n",
      "Available Ollama models:\n",
      "- all-minilm:latest\n",
      "- llama3.2:1b\n",
      "- codeqwen:7b\n",
      "- terminator:latest\n",
      "- qwen3:0.6b\n",
      "- qwen3:1.7b\n",
      "\n",
      "Using LLM model: llama3.2:1b\n",
      "Using embedding model: all-minilm\n",
      "Make sure these models are available with 'ollama pull' commands.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\demst\\AppData\\Local\\Temp\\ipykernel_61380\\1044174799.py:23: DeprecationWarning: callback_manager is deprecated. Please use callbacks instead.\n",
      "  rag_system = RAGSystem(pdf_urls=PDF_URLS)\n",
      "2025-05-24 01:26:56,649 - __main__ - INFO - Initialized RAG system with 2 PDFs\n",
      "2025-05-24 01:26:56,651 - __main__ - INFO - Loading and processing PDFs...\n",
      "2025-05-24 01:26:59,419 - __main__ - INFO - Loaded 5 pages from https://www.ine.es/daco/daco42/ecp/ecp0123.pdf\n",
      "2025-05-24 01:27:03,324 - __main__ - INFO - Loaded 37 pages from https://fundacionalternativas.org/wp-content/uploads/2023/10/PERSONAS_MIGRANTES_v02.pdf\n",
      "2025-05-24 01:27:03,331 - __main__ - INFO - Created 165 document chunks\n",
      "2025-05-24 01:27:03,333 - __main__ - INFO - Creating new vectorstore...\n",
      "2025-05-24 01:27:03,334 - __main__ - INFO - Using temporary directory for initial database creation: C:\\Users\\demst\\AppData\\Local\\Temp\\tmpkcgs9sqf\n",
      "2025-05-24 01:27:05,178 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "2025-05-24 01:27:17,659 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-05-24 01:27:17,932 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "2025-05-24 01:27:24,774 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "C:\\Users\\demst\\AppData\\Local\\Temp\\ipykernel_61380\\1117243408.py:37: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  self.vectorstore.persist()\n",
      "2025-05-24 01:27:24,996 - __main__ - INFO - Vectorstore created successfully with 165 documents\n",
      "2025-05-24 01:27:24,999 - __main__ - INFO - Testing with a control question...\n",
      "2025-05-24 01:27:25,011 - __main__ - INFO - RAG chain setup complete\n",
      "2025-05-24 01:27:25,012 - __main__ - INFO - Answering question: How many immigrants arrive each year?\n",
      "2025-05-24 01:27:25,078 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-05-24 01:27:38,986 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I understand that you are seeking information on the number of immigrants who arrive each year in Spain.\n",
      "\n",
      "According to the provided document, the estimated number of migrants arriving in Spain is around 180,000 per year (Figura 5: Número de adquisiciones de nacionalidad española de personas residentes, 2013-2022). This data is based on the information presented in Figure 6: Población extranjera por comunidades autónomas, 2022.\n",
      "\n",
      "The document also mentions that the number of migrants arriving in Spain has been steadily increasing over the years, with a significant increase from 2013 to 2022. The exact breakdown of migrant arrivals by year is not provided, but it is mentioned that there were 225,793 migrants in 2013 and 205,880 in 2022.\n",
      "\n",
      "It's worth noting that the document also provides information on the number of migrants arriving in different regions of Spain, with some areas having significantly higher numbers than others. For example, the region of Galicia has an estimated population of over 41,756 people (Figura 6), while the region of Extremadura has an estimated population of around 1 million people.\n",
      "\n",
      "Sources:\n",
      "\n",
      "* Figura 5: Número de adquisiciones de nacionalidad española de personas residentes, 2013-2022. (Figure 5)\n",
      "* Figura 6: Población extranjera por comunidades autónomas, 2022. (Figure 6)\n",
      "\n",
      "I couldn't find the information in the documents I have access to.\n",
      "\n",
      "Please let me know if you would like me to provide further clarification or details on this topic."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-24 01:27:54,695 - __main__ - INFO - Control answer received (length: 1485)\n",
      "2025-05-24 01:27:54,696 - __main__ - INFO - Launching Gradio interface...\n",
      "c:\\Users\\demst\\Desktop\\rag\\rag\\Lib\\site-packages\\gradio\\interface.py:416: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-24 01:27:55,594 - httpx - INFO - HTTP Request: GET http://127.0.0.1:7860/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "2025-05-24 01:27:55,651 - httpx - INFO - HTTP Request: HEAD http://127.0.0.1:7860/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-24 01:27:56,057 - httpx - INFO - HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "2025-05-24 01:29:00,045 - __main__ - INFO - Answering question: cual fue la nacionalidad de inmigrantes que mas recibimos\n",
      "2025-05-24 01:29:00,115 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-05-24 01:29:17,700 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Hola! Me alegra poder ayudarte con tu pregunta.\n",
      "\n",
      "La nacionalidad de los inmigrantes que más recibieron es un tema complejo y multifacético. Según el documento proporcionado, la participación de los inmigrantes en la sociedad de acogida y su integración en las instituciones públicas son fundamentales para hacer visibles sus contribuciones.\n",
      "\n",
      "De acuerdo con el texto, \"la integración implica el respeto de los valores básicos de la Unión Europea\" (CoE 1991), lo que sugiere que la nacionalidad no es un factor determinante en la integración. Además, se menciona que \"el primer PECI incorporaba la idea de establecer un 'sistema de recepción' para personas inmigrantes recién llegadas y aquellos en situaciones especialmente vulnerables\" (CoE 1991).\n",
      "\n",
      "En cuanto a las políticas públicas, particularmente en educación, empleo, servicios sociales, salud y vivienda, se enfatiza la necesidad de asegurar el acceso de la población inmigrante a estos servicios en igualdad de condiciones con la población autóctona (CoE 1991).\n",
      "\n",
      "En resumen, no se menciona explícitamente que los inmigrantes sean de una determinada nacionalidad. Sin embargo, se puede inferir que su integración y participación en la sociedad de acogida dependen de sus capacidades para adaptarse a las normas y valores de la sociedad española.\n",
      "\n",
      "Referencias:\n",
      "\n",
      "* CoE (1991). \"La política de inmigración en la Unión Europea\". En Comisión Europea."
     ]
    }
   ],
   "source": [
    "# Run the system\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "else:\n",
    "    # If running in a notebook\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
